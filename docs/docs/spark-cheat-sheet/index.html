<!DOCTYPE html> <html lang="en-US"> <head prefix="og: http://ogp.me/ns#"> <meta charset="UTF-8" /> <meta http-equiv="X-UA-Compatible" content="ie=edge" /> <meta name="viewport" content="width=device-width, initial-scale=1.0" /> <meta name="mobile-web-app-capable" content="yes" /> <meta name="apple-mobile-web-app-capable" content="yes" /> <meta name="application-name" content="Anuradha Chowdhary" /> <meta name="apple-mobile-web-app-status-bar-style" content="#fff" /> <meta name="apple-mobile-web-app-title" content="Anuradha Chowdhary" /> <title> Spark3 Cheat Sheet - Anuradha Chowdhary </title> <link rel="alternate" href="https://www.achowdhary.com/spark-cheat-sheet/" hreflang="en-US" /> <link rel="canonical" href="https://www.achowdhary.com/spark-cheat-sheet/" /> <meta name="description" content="A short collection of new funcationality in Spark3." /> <meta name="referrer" content="no-referrer-when-downgrade" /> <meta property="fb:app_id" content="" /> <meta property="og:site_name" content="Spark3 Cheat Sheet | Anuradha Chowdhary" /> <meta property="og:title" content="Spark3 Cheat Sheet | Anuradha Chowdhary" /> <meta property="og:type" content="website" /> <meta property="og:url" content="https://www.achowdhary.com/spark-cheat-sheet/" /> <meta property="og:description" content="A short collection of new funcationality in Spark3." /> <meta property="og:image" content="https://www.achowdhary.com/spark3-cheat-sheet/spark3-cheat-sheet.png" /> <meta property="og:image:width" content="640" /> <meta property="og:image:height" content="640" /> <meta name="twitter:card" content="summary" /> <meta name="twitter:title" content="Spark3 Cheat Sheet | anu2602" /> <meta name="twitter:url" content="https://www.achowdhary.com/spark-cheat-sheet/" /> <meta name="twitter:site" content="@anu2602" /> <meta name="twitter:creator" content="@anu2602" /> <meta name="twitter:description" content="A short collection of new funcationality in Spark3." /> <meta name="twitter:image" content="https://www.achowdhary.com/spark3-cheat-sheet/spark3-cheat-sheet.png" /> <link type="application/atom+xml" rel="alternate" href="https://www.achowdhary.com/feed.xml" title="Anuradha Chowdhary" /> <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png" /> <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png" /> <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png" /> <link rel="manifest" href="/assets/favicons/site.webmanifest" /> <link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#5bbad5" /> <meta name="apple-mobile-web-app-title" content="Jekyll Klise" /> <meta name="application-name" content="Jekyll Klise" /> <meta name="msapplication-TileColor" content="#da532c" /> <meta name="theme-color" content="#2c2c2c" /> <link rel="stylesheet" href="/assets/css/style.css" /> </head> <body data-theme="dark" class="notransition"> <script> const body = document.body; const data = body.getAttribute("data-theme"); const initTheme = (state) => { if (state === "dark") { body.setAttribute("data-theme", "dark"); } else if (state === "light") { body.removeAttribute("data-theme"); } else { localStorage.setItem("theme", data); } }; initTheme(localStorage.getItem("theme")); setTimeout(() => body.classList.remove("notransition"), 75); </script> <div class="navbar" role="navigation"> <nav class="menu"> <input type="checkbox" id="menu-trigger" class="menu-trigger" /> <label for="menu-trigger"> <span class="menu-icon"> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 512 512" > <path d="M64,384H448V341.33H64Zm0-106.67H448V234.67H64ZM64,128v42.67H448V128Z" /> </svg> </span> </label> <a id="mode"> <svg class="mode-sunny" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 512 512" > <title>LIGHT</title> <line x1="256" y1="48" x2="256" y2="96" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="256" y1="416" x2="256" y2="464" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="108.92" x2="369.14" y2="142.86" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="369.14" x2="108.92" y2="403.08" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="464" y1="256" x2="416" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="96" y1="256" x2="48" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="403.08" x2="369.14" y2="369.14" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="142.86" x2="108.92" y2="108.92" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <circle cx="256" cy="256" r="80" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> </svg> <svg class="mode-moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 512 512" > <title>DARK</title> <line x1="256" y1="48" x2="256" y2="96" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="256" y1="416" x2="256" y2="464" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="108.92" x2="369.14" y2="142.86" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="369.14" x2="108.92" y2="403.08" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="464" y1="256" x2="416" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="96" y1="256" x2="48" y2="256" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="403.08" y1="403.08" x2="369.14" y2="369.14" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <line x1="142.86" y1="142.86" x2="108.92" y2="108.92" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> <circle cx="256" cy="256" r="80" style="stroke-linecap:round;stroke-miterlimit:10;stroke-width:32px" /> </svg> </a> <div class="trigger"> <div class="trigger-container"><a class="menu-link" href="/">home</a><a class="menu-link" href="/posts/">posts</a><a class="menu-link" href="/about/">about</a><a class="menu-link rss" href="/feed.xml"> <svg xmlns="http://www.w3.org/2000/svg" width="17" height="17" viewBox="0 0 512 512" fill="#ED812E" > <title>RSS</title> <path d="M108.56,342.78a60.34,60.34,0,1,0,60.56,60.44A60.63,60.63,0,0,0,108.56,342.78Z" /> <path d="M48,186.67v86.55c52,0,101.94,15.39,138.67,52.11s52,86.56,52,138.67h86.66C325.33,312.44,199.67,186.67,48,186.67Z" /> <path d="M48,48v86.56c185.25,0,329.22,144.08,329.22,329.44H464C464,234.66,277.67,48,48,48Z" /> </svg> </a> </div> </div> </nav> </div> <div class="wrapper post"> <main class="page-content" aria-label="Content"> <article itemscope itemtype="https://schema.org/BlogPosting"> <header class="header"> <div class="tags"> <span itemprop="keywords"> <a class="tag" href="/tags/#yum">YUM</a>, <a class="tag" href="/tags/#howto">HOWTO</a>, <a class="tag" href="/tags/#cheatsheet">CHEATSHEET</a> </span> </div> <h1 class="header-title" itemprop="headline">Spark3 Cheat Sheet</h1> <div class="post-meta"> <time datetime="2021-05-15T11:22:42+05:30" itemprop="datePublished"> May 15, 2021 </time> <span itemprop="author" itemscope itemtype="https://schema.org/Person"> <span itemprop="name">Anuradha Chowdhary</span> </span> <time hidden datetime="" itemprop="dateModified"> May 15, 2021 </time> <span hidden itemprop="publisher" itemtype="Person">Anuradha Chowdhary</span> <span hidden itemprop="image">/spark3-cheat-sheet/spark3-cheat-sheet.png</span> <span hidden itemprop="mainEntityOfPage"><figure> <img src="spark3-cheat-sheet.png" alt="What's new in Spark3?" /> </figure> </span> </div> </header> <div class="page-content" itemprop="articleBody"> <figure> <img src="spark3-cheat-sheet.png" alt="What's new in Spark3?" /> </figure> <p>Okie, this is not really a cheatsheet. It is more about “what’s new in Spark 3?”, so more appropriate title would be “What’s new in Spark3 Cheat Sheet”. So Let’s first look at what’s new in Spark3. As with cheet sheet, we will only discuss most useful featurs, improvements that were introduced in Spark3:</p> <h1 id="performance"> <a href="#performance" class="anchor-head"></a> Performance </h1> <h4 id="1-adaptive-query-execution-aqe-"> <a href="#1-adaptive-query-execution-aqe-" class="anchor-head"></a> 1. Adaptive Query Execution (AQE) <a href="https://issues.apache.org/jira/browse/SPARK-31412" target="_blank"></a> </h4> <p>By far, this has to be the number one reason to upgrade to Spark3. Every spark developer was so looking forward to AQE improvement and they surely do not disappoint. Prior to 3.0, Spark optimized by creating an execution plan before the query execution, AQE applies a second level of optimization based on the metrics it sees with each stage.</p> <p>In Spark 3.0, the AQE framework is result of 40+ Improvements, three main ones are:</p> <ul> <li><strong>Dynamically coalescing shuffle partitions</strong> simplifies the number of shuffle partitions.</li> <li><strong>Dynamically switching join strategies</strong> partially avoids executing suboptimal plans due to missing statistics and/or size misestimation.</li> <li><strong>Dynamically optimizing skew joins</strong> can parallelize skew processing and achieve better overall performance.</li> </ul> <p>Adaptive Query Execution is disabled by default. Adaptive Query Execution is used if query meets the following criteria:</p> <ul> <li>It is not a streaming query</li> <li>It contains at least one exchange (usually when there’s a join, aggregate or window operator) or one subquery</li> </ul> <blockquote> <p>In order to enable AQE, set <code class="language-plaintext highlighter-rouge">spark.sql.adaptive.enabled</code> configuration property to <code class="language-plaintext highlighter-rouge">true</code>.</p> </blockquote> <p>After enabling Adaptive Query Execution, Spark performs 2x improvement on TPC-DS over Spark 2. There’s no need to “know” your data in advance any more. AQE will figure out the data and improve the query plan as the query runs, increasing query performance for faster analytics and system performance.</p> <h4 id="2-dynamic-partition-pruning"> <a href="#2-dynamic-partition-pruning" class="anchor-head"></a> 2. Dynamic Partition Pruning </h4> <p>Basically, dynamic partition pruning is to avoid partition scanning based on the queried results of the other query fragments. It is important for star schema queries. Spark3 implements dynamic partition pruning by adding a dynamic-partition-pruning filter if there is a partitioned table and a filter on the dimension table. The filter is then planned using a heuristic approach:</p> <ul> <li>As a broadcast relation if it is a broadcast hash join. The broadcast relation will then be transformed into a reused broadcast exchange by the ReuseExchange rule; or</li> <li>As a subquery duplicate if the estimated benefit of partition table scan being saved is greater than the estimated cost of the extra scan of the duplicated subquery; otherwise</li> <li>As a bypassed condition (true). Below shows a .</li> </ul> <figure> <img src="dpp.png" alt="DPP" /> <figcaption style="color: grey !important;"> A basic example of DPP </figcaption> </figure> <h1 id="new-features"> <a href="#new-features" class="anchor-head"></a> New Features </h1> <h4 id="3-new-structured-streaming"> <a href="#3-new-structured-streaming" class="anchor-head"></a> 3. New Structured Streaming </h4> <p>A new Structured Streaming tab to has been added to Spark UI to monitor Structured streaming applications. This tab provides the run ID, Status, Start Time, Duration for each micro-batch along with runtime statistics. This helps the developer to debug and understand what’s happening with the streaming queries. It has two sections.</p> <ul> <li>Active Streaming Queries</li> <li>Completed Streaming Queries</li> </ul> <figure> <img src="streaming-ui.png" alt="DPP" /> <figcaption style="color: grey !important;"> Structured Streaming UI </figcaption> </figure> <h4 id="4-accelerator-aware-scheduler-project-hydrogen"> <a href="#4-accelerator-aware-scheduler-project-hydrogen" class="anchor-head"></a> 4. Accelerator-aware Scheduler (Project Hydrogen) </h4> <p>GPUs and other accelerators have been widely used for accelerating special workloads, e.g., deep learning and signal processing. While users from the AI community use GPUs heavily, they often need Apache Spark to load and process large datasets and to handle complex data scenarios like streaming. Spark is not aware of GPUs and hence cannot properly request and schedule them for users. This leaves a critical gap to unify big data and AI workloads and make life simpler for end users.</p> <figure> <img src="hydrogen.png" alt="Project Hydrogen" /> <figcaption style="color: grey !important;"> Accelerating Apache Spark 3.0 with GPUs and RAPIDS </figcaption> </figure> <figure> <img src="spark2gpu.png" alt="Project Hydrogen" /> <figcaption style="color: grey !important;"> n Spark 2.x, separate clusters were needed for ETL on CPUs, and model training on GPUs. </figcaption> </figure> <figure> <img src="spark3gpu.png" alt="Project Hydrogen" /> <figcaption style="color: grey !important;"> In Apache Spark 3.0, you can now have a single pipeline, from data ingest to data preparation to model training on a GPU powered cluster. </figcaption> </figure> <h4 id="4-other-notable-features"> <a href="#4-other-notable-features" class="anchor-head"></a> 4. Other notable Features </h4> <h5 id="41-datasource-to-read-binary-files"> 4.1 Datasource to Read Binary Files </h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val df = spark.read.format("binaryFile").load("/tmp/binary/spark.png")
</code></pre></div></div> <h5 id="42-feature-to-read-recursive-folders"> 4.2 Feature to Read Recursive folders </h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    spark.read.option("recursiveFileLookup", "true").csv("/path/to/folder")
</code></pre></div></div> <h5 id="43-multiple-character-delimiter-support"> 4.3 Multiple Character Delimiter Support </h5> <p>For example, to read a CSV file with the following content.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    col1||col2||col3||col4
    val1||val2||val3||val4
    val1||val2||val3||val4
</code></pre></div></div> <p>below code can be used.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val df  = spark.read
      .option("delimiter","||")
      .option("header","true")
      .csv("/tmp/data/douplepipedata.csv")
</code></pre></div></div> <h5 id="44-dataframetail-feature"> 4.4 DataFrame.tail() feature </h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val data=spark.range(1,100).toDF("num").tail(5)
</code></pre></div></div> <h5 id="44-dataframetail-feature-1"> 4.4 DataFrame.tail() feature </h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val data=spark.range(1,100).toDF("num").tail(5)
</code></pre></div></div> <h3 id="45-new-built-in-functions"> <a href="#45-new-built-in-functions" class="anchor-head"></a> 4.5 New built-in functions </h3> <ul> <li>sinh, cosh, tanh, asinh, acosh, atanh <a href="https://issues.apache.org/jira/browse/SPARK-28133" target="_blank"></a></li> <li>any, every, some <a href="https://issues.apache.org/jira/browse/SPARK-19851" target="_blank"></a></li> <li>bit_and, bit_or <a href="https://issues.apache.org/jira/browse/SPARK-27879" target="_blank"></a></li> <li>bit_count <a href="https://issues.apache.org/jira/browse/SPARK-29491" target="_blank"></a></li> <li>bit_xor <a href="https://issues.apache.org/jira/browse/SPARK-29545" target="_blank"></a></li> <li>bool_and, bool_or <a href="https://issues.apache.org/jira/browse/SPARK-30184" target="_blank"></a></li> <li>count_if <a href="https://issues.apache.org/jira/browse/SPARK-27425" target="_blank"></a></li> <li>date_part <a href="https://issues.apache.org/jira/browse/SPARK-28690" target="_blank"></a></li> <li>extract <a href="https://issues.apache.org/jira/browse/SPARK-23903" target="_blank"></a></li> <li>forall <a href="https://issues.apache.org/jira/browse/SPARK-27905" target="_blank"></a></li> <li>from_csv <a href="https://issues.apache.org/jira/browse/SPARK-25393" target="_blank"></a></li> <li>make_date <a href="https://issues.apache.org/jira/browse/SPARK-28432" target="_blank"></a></li> <li>make_interval <a href="https://issues.apache.org/jira/browse/SPARK-29393" target="_blank"></a></li> <li>make_timestamp <a href="https://issues.apache.org/jira/browse/SPARK-28495" target="_blank"></a></li> <li>map_entries <a href="https://issues.apache.org/jira/browse/SPARK-23935" target="_blank"></a></li> <li>map_filter <a href="https://issues.apache.org/jira/browse/SPARK-23937" target="_blank"></a></li> <li>map_zip_with <a href="https://issues.apache.org/jira/browse/SPARK-23938" target="_blank"></a></li> <li>max_by, min_by <a href="https://issues.apache.org/jira/browse/SPARK-27653" target="_blank"></a></li> <li>schema_of_csv <a href="https://issues.apache.org/jira/browse/SPARK-25672" target="_blank"></a></li> <li>to_csv <a href="https://issues.apache.org/jira/browse/SPARK-25683" target="_blank"></a></li> <li>transform_keys <a href="https://issues.apache.org/jira/browse/SPARK-23939" target="_blank"></a></li> <li>transform_values <a href="https://issues.apache.org/jira/browse/SPARK-23940" target="_blank"></a></li> <li>typeof <a href="https://issues.apache.org/jira/browse/SPARK-29961" target="_blank"></a></li> <li>version <a href="https://issues.apache.org/jira/browse/SPARK-29554" target="_blank"></a></li> <li>xxhash64 <a href="https://issues.apache.org/jira/browse/SPARK-27099" target="_blank"></a></li> </ul> <h4 id="5-catalog-plugin-api"> <a href="#5-catalog-plugin-api" class="anchor-head"></a> 5. Catalog plugin API </h4> <p>This will bring multi-catalog support to Spark and allow external catalog implementations. In Spark 3 multiple catalogs can be added:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    spark.sql.catalog.catalog1=...
    spark.sql.catalog.catalog1.type=...
    spark.sql.catalog.catalog1.warehouse=...
    spark.sql.catalog.catalog2=...
    spark.sql.catalog.catalog2.type=...
    spark.sql.catalog.catalog2.warehouse=...
</code></pre></div></div> <p>and can be used in query:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    spark.sql("SELECT * FROM catalog1.db1.table1")
</code></pre></div></div> <h1 id="upgrades-and-enhancements"> <a href="#upgrades-and-enhancements" class="anchor-head"></a> Upgrades and Enhancements </h1> <h4 id="6-improvements-on-pandas-udf-api"> <a href="#6-improvements-on-pandas-udf-api" class="anchor-head"></a> 6. Improvements on pandas UDF API </h4> <p>Pandas UDFs (User-Defined Functions) are probably one of the most significant Pandsa improvement added to Spark since version 2.3 as they allow users to leverage pandas API. The newest release of Apache Spark introduced a new interface of Pandas UDFs with Python type hints. Example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    import pandas as pd
    from pyspark.sql.functions import pandas_udf

    @pandas_udf('long')
    def pandas_subtract_unit(s: pd.Series) -&gt; pd.Series:
        return s - 1
</code></pre></div></div> <h4 id="7-switch-to-proleptic-gregorian-calendar"> <a href="#7-switch-to-proleptic-gregorian-calendar" class="anchor-head"></a> 7. Switch to Proleptic Gregorian calendar </h4> <p>Earlier version of Spark supports Dates in Julian and Gregorian calendar: For dates before 1582, the Julian calendar was used, for dates, after 1582 the Gregorian calendar was used. This is similar to Dates in JDK 7 and before which uses java.sql.Date API. From JDK 8, a new Proleptic Gregorian calendar has been introduced with java.time.LocalDate API.</p> <h4 id="8-better-ansi-sql-compatible-"> <a href="#8-better-ansi-sql-compatible-" class="anchor-head"></a> 8. Better ANSI SQL compatible <a href="https://spark.apache.org/docs/3.0.0/sql-ref-ansi-compliance.html" target="_blank"></a> </h4> <p>Since Spark 3.0, Spark SQL introduces two experimental options to comply with the SQL standard: <code class="language-plaintext highlighter-rouge">spark.sql.ansi.enabled</code> and <code class="language-plaintext highlighter-rouge">spark.sql.storeAssignmentPolicy</code>.</p> <p>When <code class="language-plaintext highlighter-rouge">spark.sql.ansi.enabled</code> is set to true, Spark SQL follows the standard in basic behaviours (e.g., arithmetic operations, type conversion, SQL functions and SQL parsing). Moreover, Spark SQL has an independent option to control implicit casting behaviours when inserting rows in a table. The casting behaviours are defined as store assignment rules in the standard.</p> <p>When <code class="language-plaintext highlighter-rouge">spark.sql.storeAssignmentPolicy</code> is set to ANSI, Spark SQL complies with the ANSI store assignment rules. This is a separate configuration because its default value is ANSI, while the configuration spark.sql.ansi.enabled is disabled by default.</p> <h4 id="9--upgrades"> <a href="#9--upgrades" class="anchor-head"></a> 9. Upgrades </h4> <ul> <li>Hadoop 3 Upgrade</li> <li>JDK 11 Support</li> <li>Python3</li> <li>Scala 2.12</li> <li>Kfka 2.4.1</li> </ul> <p>If you still think this is not a cheat sheet, here is one of <a href="http://datacamp-community-prod.s3.amazonaws.com/acfa4325-1d43-4542-8ce4-bea2d287db10" target="_blank">my favorite Spark 3 Cheat Sheet</a>.</p> <h3 id="reference"> <a href="#reference" class="anchor-head"></a> Reference </h3> <ol> <li><a href="https://spark.apache.org/releases/spark-release-3-0-0.html" target="_blank"> Spark 3.0.3 Release Changelog </a></li> <li><a href="https://issues.apache.org/jira/browse/SPARK-31412" target="_blank"> Adaptive Query Execution </a></li> <li><a href="https://databricks.com/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html" target="_blank"> Databricks Spark 3.0 blog </a></li> <li><a href="https://issues.apache.org/jira/browse/SPARK-11150" target="_blank"> Dynamic Partition Pruning </a></li> <li><a href="https://spark.apache.org/docs/3.0.0/web-ui.html#structured-streaming-tab" target="_blank"> Structured Streaming Tab </a></li> <li><a href="https://issues.apache.org/jira/browse/SPARK-24615" target="_blank"> SPIP: Accelerator-aware task scheduling for Spark </a></li> <li><a href="https://databricks.com/session_na20/deep-dive-into-gpu-support-in-apache-spark-3-x" target="_blank"> Deep Dive into GPU Support </a></li> <li><a href="https://developer.nvidia.com/blog/accelerating-apache-spark-3-0-with-gpus-and-rapids/" target="_blank"> Accelerating Apache Spark 3.0 with GPUs and RAPIDS </a></li> <li><a href="https://docs.google.com/document/d/1zLFiA1VuaWeVxeTDXNg8bL6GP3BVoOZBkewFtEnjEoo/edit#" target="_blank">Spark API for Table Metadata</a></li> <li><a href="https://books.japila.pl/spark-sql-internals/new-and-noteworthy/catalog-plugin-api-and-multi-catalog-support/" target="_blank"> Catalog Plugin APi by example</a></li> <li><a href="https://spark.apache.org/docs/latest/sql-migration-guide.html" target="_blank"> Spark3 SQL Migration Guide</a></li> <li><a href="https://docs.google.com/document/d/1-kV0FS_LF2zvaRh_GhkV32Uqksm_Sq8SvnBBmRyxm30/edit" target="_blank"> Revisiting Pandas UDF</a></li> <li><a href="https://spark.apache.org/docs/3.0.0/sql-ref-ansi-compliance.html" target="_blank">Better ANSI SQL compatibality in Spark 3</a></li> </ol> </div> </article> </main> <nav class="post-nav"> <a class="post-nav-item post-nav-prev" href="/juppyter-hub-disable-console-access/" > <div class="nav-arrow">Previous</div> <span class="post-title">Disable Console Access for Jupyter Hub.</span> </a> <a class="post-nav-item post-nav-next" href="/monkey-patching/"> <div class="nav-arrow">Next</div> <span class="post-title">Python Monkey Patching</span> </a> </nav> <nav class="post-nav"></nav> <div id="disqus_thread"></div> <script> (function() { var d = document, s = d.createElement('script'); s.src = 'https://achowdhary.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <footer class="footer"> <a class="footer_item" href="/thanks">ack.</a> <a class="footer_item" href="javascript::void(0)">resume</a> <a class="footer_item" href="/feed.xml">rss</a> <!--span class="footer_item">&copy; 2022</span--> <small class="footer_copyright"> &copy 2022 Anuradha Chowdhary </small> </footer> <script src="/assets/js/main.js" defer="defer"></script> </div> </body> </html>
